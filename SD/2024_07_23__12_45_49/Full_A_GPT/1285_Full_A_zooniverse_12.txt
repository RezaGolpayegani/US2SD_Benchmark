To create a detailed sequence diagram for the user story "As a user, I want to identify persons in videos, and receive related information about them" in the context of the Advanced Media Identification & Discovery Platform (AMIDP) using PlantUML notation, we first need to outline the interactions between the system components and the user. 

Given the complexity of the AMIDD platform, this sequence will include user interactions, backend processing, and interactions with AI/ML models for person identification and metadata retrieval. 

The following is a basic sequence diagram in PlantUML format that demonstrates these interactions:

```plantuml
@startuml
participant User
participant "UI Interface" as UI
participant "Video Processing Module" as VPM
participant "AI/ML Model" as AI
participant "Database" as DB
participant "Information Retrieval System" as IRS

User -> UI : Uploads video for identification
UI -> VPM : Sends video for processing
activate VPM

VPM -> AI : Extracts faces/figures
activate AI
AI -> AI : Identifies persons
deactivate AI

AI -> DB : Queries metadata for identified persons
activate DB
DB --> AI : Returns metadata
deactivate DB

AI --> VPM : Sends identified persons and metadata
deactivate VPM
VPM --> UI : Displays identified persons and related information
UI --> User : Shows results and related information

User -> UI : Requests more information on a person
UI -> IRS : Fetches additional data
activate IRS
IRS -> DB : Queries for more detailed information and related content
activate DB
DB --> IRS : Returns detailed information and related content
deactivate DB
IRS --> UI : Sends detailed information and content to UI
UI --> User : Displays detailed information and related content

@enduml
```
This diagram illustrates the basic flow from when a user uploads a video for person identification until they receive related information about the identified individuals. Here's a brief walkthrough of the process:

1. **User uploads a video:** The user initiates the process by uploading a video through the UI Interface.
2. **Video Processing Module (VPM) processes the video:** The UI Interface sends the video to the VPM, where the AI/ML Model is called upon to extract and identify persons in the video.
3. **AI/ML Model identifies persons and retrieves metadata:** The AI/ML Model identifies persons in the video and queries the Database for metadata related to these identified individuals.
4. **User views identified persons and related information:** The identified persons along with their basic related information are displayed back to the user through the UI Interface.
5. **User requests more information:** If the user requests more detailed information on a particular person, this request is processed by the Information Retrieval System, which fetches and displays more comprehensive data and related content.

Please note, this sequence diagram provides a simplified view of the process. The actual implementation might include additional steps like authentication, error handling, and data caching for efficiency and security purposes.